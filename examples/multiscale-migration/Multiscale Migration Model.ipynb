{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiscale Migration Model\n",
    "\n",
    "This notebook implements our model using `numpy` and `pandas` (with `xlrd`). It has been tested to run on Python 3.6. To start, import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import e\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of datasets used in this model. They can all be found in the `/data` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shortcut functions helps locate these data files easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_path(name):\n",
    "    \"\"\"\n",
    "    Shortcut function to get the relative path to the directory\n",
    "    which contains the data.\n",
    "    \"\"\"\n",
    "    return \"./data/%s\" % name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions will be useful later when pulling in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_codes():\n",
    "    \"\"\"\n",
    "    Build country rows from their names, ISO codes, and Numeric\n",
    "    Country Codes.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pd.read_csv(\n",
    "            file_path(\n",
    "                \"Country_List_ISO_3166_Codes_Latitude_Longitude.csv\"),\n",
    "            usecols=[0, 2, 3],\n",
    "            index_col=1,\n",
    "            keep_default_na=False))\n",
    "\n",
    "def freedom_index():\n",
    "    \"\"\"\n",
    "    Read data from the Freedom Index.\n",
    "    \"\"\"\n",
    "    # TODO: Add xlrd to requirements.\n",
    "    xl = pd.ExcelFile(file_path(\"Freedom_index.xlsx\"))\n",
    "    return xl.parse(1)\n",
    "\n",
    "def ab_values():\n",
    "    \"\"\"\n",
    "    Read generated A/B values for each country.\n",
    "    \"\"\"\n",
    "    return pd.read_excel(file_path(\"A&B values for RTS.xlsx\")).T\n",
    "\n",
    "def passport_index():\n",
    "    \"\"\"\n",
    "    Read data from the Passport Index.\n",
    "    \"\"\"\n",
    "    return pd.read_excel(file_path(\"PassportIndex.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify this depending on how many table rows you want to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, it is time to start processing the data.\n",
    "\n",
    "### A/B Values\n",
    "\n",
    "These values are used in the return to skill function. These values are based on each country's income distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_codes = pd.read_csv(file_path(\"wb-codes.csv\"), index_col=0)\n",
    "ab = ab_values()\n",
    "ab.index = [wb_codes[wb_codes.index == x][\"ISO3\"][0] for x in ab_values().index]\n",
    "ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance\n",
    "\n",
    "The great circle distance between the average latitude and longitude of each country is used to determine distance between each pair of countries. A greater distance between countries corresponds to a greater cost of migration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_frame = pd.read_csv(file_path(\"Country_List_ISO_3166_Codes_Latitude_Longitude.csv\"),\n",
    "                                       usecols=[2,4,5],\n",
    "                                       index_col=0,\n",
    "                                       keep_default_na=False)\n",
    "locations = [(x[1][0], x[1][1]) for x in distance_frame.iterrows()]\n",
    "rows = []\n",
    "for i in range(len(locations)):\n",
    "    row = []\n",
    "    for loc in locations:\n",
    "        row.append(haversine(loc, locations[i]))\n",
    "    rows.append(row)\n",
    "distance = pd.DataFrame(rows, distance_frame.index, distance_frame.index)\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freedom Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cc[cc['Country'] == x][\"Alpha-3 code\"] if len(cc[cc['Country'] == x]) > 0 else x for x in fi['Country']]\n",
    "codes = []\n",
    "other_codes = pd.read_csv(file_path(\"other.csv\"), index_col=0)\n",
    "cc = country_codes()\n",
    "fi = freedom_index()\n",
    "for country in fi['Country']:\n",
    "    if len(cc[cc['Country'] == country]):\n",
    "        codes.append(cc[cc['Country'] == country].index[0])\n",
    "    elif len(other_codes[other_codes.index == country]):\n",
    "        codes.append(other_codes[other_codes.index == country][\"ISO\"][0])\n",
    "    else:\n",
    "        print(country)\n",
    "fi['Country'] = codes\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passport Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = passport_index()\n",
    "codes = []\n",
    "other_codes = pd.read_csv(file_path(\"other.csv\"), index_col=0)\n",
    "for country in pi['Country']:\n",
    "    if len(cc[cc['Country'] == country]):\n",
    "        codes.append(cc[cc['Country'] == country].index[0])\n",
    "    elif len(other_codes[other_codes.index == country]):\n",
    "        codes.append(other_codes[other_codes.index == country][\"ISO\"][0])\n",
    "    else:\n",
    "        print(country)\n",
    "pi['Country'] = codes\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passport_index = pi.set_index(\"Country\")\n",
    "freedom_index = fi.set_index(\"Country\")\n",
    "#pd.concat([ab, passport_index, freedom_index])\n",
    "data = ab.join(passport_index).join(freedom_index).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_barriers = 2/(1/data['Total Aggr']/sum(1/data['Total Aggr']) +\n",
    " data['Rank (1 = most welcoming)']/sum(data['Rank (1 = most welcoming)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_barriers /= sum(political_barriers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Language\n",
    "\n",
    "Agents are assigned proficiency in languages spoken in their origin country. Mov-\n",
    "ing to a country with entirely new languages presents a higher migration cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_csv = pd.read_csv(file_path(\"languages.csv\"), index_col=0)\n",
    "# TODO: '' why?\n",
    "lang_sets = [set([str(y).strip() for y in x[1] if y is not ' ']) for x in lang_csv.iterrows()]\n",
    "lang_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = []\n",
    "for s in lang_sets:\n",
    "    o = []\n",
    "    for i in range(len(lang_sets)):\n",
    "        o.append(len(lang_sets[i].intersection(s)) >= 1)\n",
    "    overlap.append(o)\n",
    "lang_data = pd.DataFrame(overlap)\n",
    "lang_data.columns = lang_csv.index\n",
    "lang_data.index = lang_csv.index\n",
    "lang_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_data = pd.read_csv(file_path(\"CIA_Unemployment.csv\"), index_col=1)\n",
    "\n",
    "unemployment_data.index\n",
    "codes = []\n",
    "other_codes = pd.read_csv(file_path(\"other.csv\"), index_col=0)\n",
    "for country in unemployment_data.index:\n",
    "    if len(cc[cc['Country'] == country]):\n",
    "        codes.append(cc[cc['Country'] == country].index[0])\n",
    "    elif len(other_codes[other_codes.index == country]):\n",
    "        codes.append(other_codes[other_codes.index == country][\"ISO\"][0])\n",
    "    else:\n",
    "        print(country)\n",
    "        codes.append(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_data.index = codes\n",
    "unemployment_pd = pd.DataFrame([(x[0], x[1][1]) for x in unemployment_data.iterrows() if len(x[0]) <= 3])\n",
    "unemployment_pd.columns = [\"Country\", \"Unemployment Rate\"]\n",
    "unemployment_pd.index = unemployment_pd[\"Country\"]\n",
    "unemployment_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UN Migration History\n",
    "\n",
    "This one is a bit more complicated because it is a matrix, not a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pd = pd.read_excel(\n",
    "        file_path(\n",
    "            \"UN_MigrantStockByOriginAndDestination_2015.xlsx\"\n",
    "        ),\n",
    "        skiprows=15\n",
    "    )\n",
    "un_pd.index = un_pd['Unnamed: 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = un_pd.iloc[:,1]\n",
    "un_codes = un_pd.iloc[:,3]\n",
    "names_to_un_codes = {names[i]: un_codes[i] for i in range(len(names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pd = un_pd.iloc[8:275,8:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = []\n",
    "missing = []\n",
    "for code in [names_to_un_codes[x] for x in un_pd.columns.values]:\n",
    "    if len(cc[cc['Numeric code'] == code]):\n",
    "        codes.append(cc[cc['Numeric code'] == code].index[0])\n",
    "    #elif len(other_codes[other_codes['Code'] == country]):\n",
    "    #    codes.append(other_codes[other_codes['Code'] == country][\"ISO\"][0])\n",
    "    else:\n",
    "        missing.append(code)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to drop these\n",
    "drop = [x for x in un_pd.columns.values if x not in names_to_un_codes.keys() or names_to_un_codes[x] in missing]\n",
    "print(drop)\n",
    "un_pd = un_pd.drop(drop, axis=1)\n",
    "un_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "for code in [names_to_un_codes[x] for x in un_pd.index]:\n",
    "    if len(cc[cc['Numeric code'] == code]) == 0:\n",
    "        #codes.append(cc[cc['Numeric code'] == code].index[0])\n",
    "    #elif len(other_codes[other_codes['Code'] == country]):\n",
    "    #    codes.append(other_codes[other_codes['Code'] == country][\"ISO\"][0])\n",
    "    #else:\n",
    "        missing.append(code)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [x for x in un_pd.index if x not in names_to_un_codes.keys() or names_to_un_codes[x] in missing]\n",
    "print(drop)\n",
    "un_pd = un_pd.drop(drop, axis=0)\n",
    "un_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pd.index = [cc[cc['Numeric code'] == names_to_un_codes[x]].index[0] for x in un_pd.index]\n",
    "un_pd.columns = [cc[cc['Numeric code'] == names_to_un_codes[x]].index[0] for x in un_pd.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pd.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ab.index).difference(set(un_pd.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pd.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ab.index).difference(set(fi['Country']))\n",
    "# TODO: Replace values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab[ab.index=='SSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {\n",
    "    'GAZ': None, # May need to be changed.\n",
    "    'ROM': 'ROU',\n",
    "    'SDN': None, # For now, Sudan\n",
    "    'SSD': None, # and South Sudan are being dropped.\n",
    "    'TMP': 'TLS', # This should be fixed.\n",
    "    'ZAR': 'COD'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(ab)):\n",
    "    row = []\n",
    "    val = ab['A'][i]\n",
    "    for value in ab['A']:\n",
    "        row.append(val - value)\n",
    "    rows.append(row)\n",
    "np.array(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data = pd.DataFrame(rows)\n",
    "a_data.columns = ab.index\n",
    "a_data.index = ab.index\n",
    "a_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(ab)):\n",
    "    row = []\n",
    "    val = ab['B'][i]\n",
    "    for value in ab['B']:\n",
    "        row.append(val - value)\n",
    "    rows.append(row)\n",
    "np.array(rows)\n",
    "b_data = pd.DataFrame(rows)\n",
    "b_data.columns = ab.index\n",
    "b_data.index = ab.index\n",
    "b_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(fi)):\n",
    "    row = []\n",
    "    val = fi['Total Aggr'][i]\n",
    "    for value in fi['Total Aggr']:\n",
    "        row.append(val - value)\n",
    "    rows.append(row)\n",
    "freedom_index = pd.DataFrame(rows)\n",
    "freedom_index.columns = fi['Country']\n",
    "freedom_index.index = fi['Country']\n",
    "freedom_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "pi.index = pi[\"Country\"]\n",
    "for i in range(len(pi)):\n",
    "    row = []\n",
    "    val = pi['Rank (1 = most welcoming)'][i]\n",
    "    for value in pi['Rank (1 = most welcoming)']:\n",
    "        row.append(val - value)\n",
    "    rows.append(row)\n",
    "passport_index = pd.DataFrame(rows)\n",
    "passport_index.columns = pi['Country']\n",
    "#passport_index[\"Country\"] = pi[\"Country\"]\n",
    "passport_index.index = pi['Country']\n",
    "passport_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i in range(len(unemployment_pd)):\n",
    "    row = []\n",
    "    val = unemployment_pd[\"Unemployment Rate\"][i]\n",
    "    for value in unemployment_pd[\"Unemployment Rate\"]:\n",
    "        row.append(val - value)\n",
    "    rows.append(row)\n",
    "unemployment_index = pd.DataFrame(rows)\n",
    "unemployment_index.index = unemployment_pd.index\n",
    "unemployment_index.columns = unemployment_pd.index\n",
    "unemployment_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unemployment_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(unemployment_index.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(freedom_index.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the countries which overlap between all datasets?\n",
    "intersection = set(a_data.columns).intersection(\n",
    "    set(un_pd.columns)\n",
    ").intersection(\n",
    "    set(freedom_index.columns)\n",
    ").intersection(\n",
    "    set(unemployment_index.index)\n",
    ").intersection(\n",
    "    set(lang_data.index)\n",
    ")\n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter down the matrixes to only the intersections between the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passport_index.filter(items=intersection).filter(items=intersection, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"un\"] = un_pd.fillna(1).filter(items=intersection).filter(items=intersection, axis=0)\n",
    "all_data[\"a\"] = a_data.filter(items=intersection).filter(items=intersection, axis=0)\n",
    "all_data[\"b\"] = b_data.filter(items=intersection).filter(items=intersection, axis=0)\n",
    "all_data[\"freedom\"] = freedom_index.filter(items=intersection).filter(items=intersection, axis=0)\n",
    "all_data[\"passport\"] = passport_index.filter(items=intersection).filter(items=intersection, axis=0)\n",
    "all_data[\"distance\"] = distance.filter(items=intersection).filter(items=intersection, axis=0)\n",
    "all_data[\"unemployment\"] = unemployment_index.filter(items=intersection).filter(items=intersection, axis=0)\n",
    "all_data[\"language\"] = lang_data.filter(items=intersection).filter(items=intersection, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"unemployment\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I start working on fitting the data to the model as described in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula: Ae^(Bx)\n",
    "x = 40\n",
    "all_data[\"a\"] * e ** (all_data[\"b\"] * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv(migration history)\n",
    "pd.DataFrame(np.linalg.pinv(all_data[\"un\"].values), all_data[\"un\"].columns, all_data[\"un\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Political barriers\n",
    "freedom_index_inverse =pd.DataFrame(np.linalg.pinv(all_data[\"freedom\"].values), all_data[\"freedom\"].columns, all_data[\"freedom\"].index)\n",
    "political_barriers = all_data[\"passport\"] + freedom_index_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance\n",
    "\n",
    "all_data[\"distance\"] / max(all_data[\"distance\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Migration History\n",
    "\n",
    "# max(all_data[\"un\"].max())\n",
    "1 - (all_data[\"un\"]) / max(all_data[\"un\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Language\n",
    "\n",
    "1 - all_data[\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Political barriers\n",
    "\n",
    "# This goes over 100. Is that a problem?\n",
    "# Check with John about this one.\n",
    "(0.5 * all_data[\"passport\"] / max(all_data[\"passport\"].max())) + (0.5 * (1-all_data[\"freedom\"]) / 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
